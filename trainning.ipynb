{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11700916,"sourceType":"datasetVersion","datasetId":7344370}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport glob\nimport json\nimport pandas as pd\n\n\nDATA_DIR = '/kaggle/input/finefs/annotation/annotation'  # adjust as needed\n\n\nelement_rows    = []\ncomponent_rows  = []\n\n\nfor json_path in glob.glob(os.path.join(DATA_DIR, '*.json')):\n    with open(json_path, 'r') as f:\n        data = json.load(f)\n    \n    \n    sample_id = os.path.splitext(os.path.basename(json_path))[0]\n    \n    \n    for elem_key, elem in data.get('executed_element', {}).items():\n        element_rows.append({\n            'sample_id':    sample_id,\n            'element_key':  elem_key,\n            'element_name': elem.get('element'),\n            'goe':          elem.get('goe'),\n            'coarse_class': elem.get('coarse_class'),\n            'jump_comb':    elem.get('jump_comb'),\n            'panel_score':  elem.get('score_of_pannel')\n        })\n    \n   \n    for comp_key, comp in data.get('program_component', {}).items():\n        component_rows.append({\n            'sample_id':   sample_id,\n            'component':   comp_key,\n            'panel_score': comp.get('score_of_pannel')\n        })\n\n\ndf_elements   = pd.DataFrame(element_rows)\ndf_components = pd.DataFrame(component_rows)\n\n\ndf_elements.to_csv('elements_summary.csv', index=False)\ndf_components.to_csv('components_summary.csv', index=False)\n\n\nprint(\"=== Elements DataFrame ===\")\nprint(df_elements.head())\n\nprint(\"\\n=== Components DataFrame ===\")\nprint(df_components.head(10))","metadata":{"execution":{"iopub.status.busy":"2025-05-06T21:24:13.273288Z","iopub.execute_input":"2025-05-06T21:24:13.274073Z","iopub.status.idle":"2025-05-06T21:24:20.162368Z","shell.execute_reply.started":"2025-05-06T21:24:13.274046Z","shell.execute_reply":"2025-05-06T21:24:20.161496Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\nnpz_path = '/kaggle/input/finefs/skeleton/skeleton/1.npz'  # pick any file\nwith np.load(npz_path) as archive:\n    print(\"Available keys:\", archive.keys())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T17:24:33.484305Z","iopub.execute_input":"2025-05-06T17:24:33.484575Z","iopub.status.idle":"2025-05-06T17:24:33.490054Z","shell.execute_reply.started":"2025-05-06T17:24:33.484547Z","shell.execute_reply":"2025-05-06T17:24:33.489202Z"}},"outputs":[{"name":"stdout","text":"Available keys: KeysView(NpzFile '/kaggle/input/finefs/skeleton/skeleton/1.npz' with keys: reconstruction)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"\n\nimport torch \n\n\nuser_npz_dir = '/kaggle/input/finefs/skeleton/skeleton'\nuser_scaler_save_path_base = 'lstm_feature_scaler_focused' \nuser_best_model_path = 'best_lstm_model_state_focused.pth' \nuser_best_scaler_path = 'best_lstm_scaler_focused.joblib' \nuser_model_save_dir = './lstm_trained_models_focused' \n\n# Device\nuser_device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Component names (usually fixed)\nuser_components_list = ['skating_skills', 'transitions', 'performance', 'composition', 'interpretation']\nuser_output_dim = len(user_components_list) \n\n\nuser_tuning_configuration_templates = [\n    \n    {\n        'name': 'lstm_lr_batch_wd',\n        'params': {\n            'MODEL_TYPE': 'LSTM', \n            'SEQ_LEN': 1000, \n            'INCLUDE_VELOCITIES': True, \n            'INCLUDE_ACCELERATIONS': False, \n            'POSITION_ENCODING': 'absolute', \n            'MODEL_POOLING_STRATEGY': 'last',\n            'HIDDEN_DIM': 256, \n            'NUM_LAYERS': 2,   \n            'LSTM_DROPOUT': 0.3, \n            'FC_DROPOUT': 0.4, \n            'OPTIMIZER_TYPE': 'AdamW', \n\n            \n            'LEARNING_RATE': (1e-4, 5e-4, 1e-3), \n            'BATCH_SIZE': (16, 32),              \n            'WEIGHT_DECAY': (0.0, 1e-4, 1e-5),   \n\n            'GRADIENT_CLIP_VALUE': 1.0, \n            'NUM_EPOCHS': 10, \n            'PATIENCE': 5, \n            'MIN_DELTA': 0.0001, \n        }\n    }, \n\n    \n    {\n        'name': 'lstm_arch_dropout',\n        'params': {\n            'MODEL_TYPE': 'LSTM',\n            'SEQ_LEN': 1000,\n            'INCLUDE_VELOCITIES': True,\n            'INCLUDE_ACCELERATIONS': False,\n            'POSITION_ENCODING': 'absolute',\n            'MODEL_POOLING_STRATEGY': 'last',\n\n           \n            'HIDDEN_DIM': (128, 256), \n            'NUM_LAYERS': (2, 3),   \n            'LSTM_DROPOUT': (0.2, 0.4), \n            'FC_DROPOUT': (0.3, 0.5), \n\n            'OPTIMIZER_TYPE': 'AdamW',\n            'LEARNING_RATE': 1e-4, \n            'BATCH_SIZE': 16, # Fixed\n            'WEIGHT_DECAY': 1e-4, # Fixed\n            'GRADIENT_CLIP_VALUE': 1.0,\n            'NUM_EPOCHS': 10,\n            'PATIENCE': 5,\n            'MIN_DELTA': 0.0001,\n        }\n    }, \n\n\n\nprint(\"Configuration parameters and focused LSTM tuning templates defined (~42 runs total).\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T21:24:20.163983Z","iopub.execute_input":"2025-05-06T21:24:20.164264Z","iopub.status.idle":"2025-05-06T21:24:28.210876Z","shell.execute_reply.started":"2025-05-06T21:24:20.164242Z","shell.execute_reply":"2025-05-06T21:24:28.209984Z"}},"outputs":[{"name":"stdout","text":"Configuration parameters and focused LSTM tuning templates defined (~42 runs total).\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nimport matplotlib.pyplot as plt\nimport joblib \nimport itertools \n\n\n\n\nNPZ_DIR = user_npz_dir\nSCALER_SAVE_PATH_BASE = user_scaler_save_path_base\nBEST_MODEL_PATH = user_best_model_path\nBEST_SCALER_PATH = user_best_scaler_path\nDEVICE = user_device\nCOMPONENTS_LIST = user_components_list\nOUTPUT_DIM = user_output_dim # Should match len(COMPONENTS_LIST)\n\nprint(f\"Script is using device: {DEVICE}\")\nprint(f\"Script is using NPZ_DIR: {NPZ_DIR}\")\n\n\n\ndef expand_configurations(template_configs):\n    expanded_configs = []\n    for template in template_configs:\n        template_name = template.get('name', 'unnamed_template')\n        template_params = template.get('params', {})\n\n        \n        multi_value_params = {\n            k: v for k, v in template_params.items()\n            if isinstance(v, (tuple, list))\n        }\n        single_value_params = {\n            k: v for k, v in template_params.items()\n            if not isinstance(v, (tuple, list))\n        }\n\n        if not multi_value_params:\n            expanded_configs.append({'name': template_name, 'params': template_params.copy()}) \n        else:\n            param_names = list(multi_value_params.keys())\n            param_values = list(multi_value_params.values())\n\n            for i, combination in enumerate(itertools.product(*param_values)):\n                new_run_params = single_value_params.copy()\n                combination_dict = dict(zip(param_names, combination))\n                new_run_params.update(combination_dict)\n\n                # Generate a unique name for this specific run\n                param_suffix = \"_\".join([f\"{k}{v}\" for k, v in combination_dict.items()])\n                param_suffix = param_suffix.replace('.', 'p').replace('-', 'm').replace('e-', 'e').replace('[','').replace(']','').replace('(','').replace(')','').replace(',', '_').replace(' ', '')\n                # Ensure name is not too long for filenames\n                if len(param_suffix) > 50: param_suffix = param_suffix[:50] + '...'\n                new_run_name = f\"{template_name}_{param_suffix}_{i+1}\"\n\n                expanded_configs.append({'name': new_run_name, 'params': new_run_params})\n\n    return expanded_configs\n\n\n\nclass SkeletonPCSDataset(Dataset):\n    def __init__(self, manifest_df, npz_dir, seq_len, components_list,\n                 scaler=None, include_velocities=True):\n        self.df = manifest_df\n        self.npz_dir = npz_dir\n        self.seq_len = seq_len\n        self.components_list = components_list\n        self.include_velocities = include_velocities\n        self.scaler = scaler\n\n    def _load_and_process_features(self, sample_id_str):\n        file_path = os.path.join(self.npz_dir, sample_id_str + '.npz')\n        try:\n            if not os.path.exists(file_path):\n                \n                 return None\n\n            data = np.load(file_path)['reconstruction']\n        except Exception as e:\n            \n            return None\n\n        T, J, C = data.shape\n        if T == 0:\n           \n            return None\n\n        x_coords = data.reshape(T, J * C).astype(np.float32)\n\n        if self.include_velocities:\n            if T > 1:\n                velocities = np.diff(x_coords, axis=0)\n                velocities = np.vstack([np.zeros((1, J * C), dtype=np.float32), velocities])\n            else:\n                velocities = np.zeros_like(x_coords, dtype=np.float32)\n            x_combined = np.concatenate([x_coords, velocities], axis=1)\n        else:\n            x_combined = x_coords\n\n        return x_combined\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        sample_id_str = str(row['sample_id']).replace('.npz', '')\n\n        x_processed_unscaled = self._load_and_process_features(sample_id_str)\n\n        if x_processed_unscaled is None:\n            base_coord_dim_assumption = 17 * 3\n            features_dim = base_coord_dim_assumption * (2 if self.include_velocities else 1)\n           \n            return torch.zeros(self.seq_len, features_dim), torch.zeros(len(self.components_list))\n\n        current_T, current_features_dim = x_processed_unscaled.shape\n\n        if self.scaler is not None and hasattr(self.scaler, 'mean_') and self.scaler.mean_ is not None:\n            try:\n                if current_features_dim != self.scaler.mean_.shape[0]:\n                     print(f\"Warning: Feature dimension mismatch for sample {sample_id_str}. Data has {current_features_dim} features, scaler expects {self.scaler.mean_.shape[0]}. Skipping scaling.\")\n                     x_scaled = x_processed_unscaled\n                else:\n                    x_scaled = self.scaler.transform(x_processed_unscaled)\n            except Exception as e:\n                print(f\"Error scaling features for {sample_id_str}: {e}. Using unscaled features.\")\n                x_scaled = x_processed_unscaled\n        else:\n            x_scaled = x_processed_unscaled\n\n        if current_T < self.seq_len:\n            pad_shape = (self.seq_len - current_T, current_features_dim)\n            pad = np.zeros(pad_shape, dtype=np.float32)\n            x_final = np.vstack([x_scaled, pad])\n        else:\n            x_final = x_scaled[:self.seq_len]\n\n        y = row[self.components_list].values.astype(np.float32)\n        return torch.from_numpy(x_final), torch.from_numpy(y)\n\n\ndef fit_feature_scaler(manifest_df, npz_dir, include_velocities):\n    print(\"Collecting data to fit the scaler...\")\n    all_features_list = []\n    temp_dataset = SkeletonPCSDataset(manifest_df, npz_dir, 1, ['dummy'],\n                                      scaler=None, include_velocities=include_velocities)\n\n    valid_samples_count = 0\n    for idx in range(len(manifest_df)):\n        features = temp_dataset._load_and_process_features(manifest_df.iloc[idx]['sample_id'].replace('.npz', ''))\n        if features is not None and features.shape[0] > 0:\n             all_features_list.append(features)\n             valid_samples_count += 1\n\n    if not all_features_list:\n        print(\"Warning: No features collected to fit the scaler.\")\n        return None\n\n    all_features_flat = np.vstack(all_features_list)\n    print(f\"Fitting scaler on {all_features_flat.shape[0]} samples with {all_features_flat.shape[1]} features each from {valid_samples_count} files.\")\n\n    scaler = StandardScaler()\n    scaler.fit(all_features_flat)\n    return scaler\n\n\nclass LSTMRegressor(nn.Module):\n    def __init__(self, input_dim, hidden_dim, num_layers, output_dim, lstm_dropout, fc_dropout, pooling_strategy='mean'):\n        super().__init__()\n        self.pooling_strategy = pooling_strategy\n        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers,\n                            batch_first=True, bidirectional=True,\n                            dropout=lstm_dropout if num_layers > 1 else 0)\n\n        fc_input_dim = hidden_dim * 2\n\n        self.fc = nn.Sequential(\n            nn.Linear(fc_input_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(fc_dropout),\n            nn.Linear(hidden_dim, hidden_dim // 2),\n            nn.ReLU(),\n            nn.Dropout(fc_dropout),\n            nn.Linear(hidden_dim // 2, output_dim)\n        )\n\n\n    def forward(self, x):\n        outs, (hn, cn) = self.lstm(x)\n\n        if self.pooling_strategy == 'mean':\n            pooled = torch.mean(outs, dim=1)\n        elif self.pooling_strategy == 'last':\n            pooled = torch.cat((hn[-2,:,:], hn[-1,:,:]), dim=1)\n        else:\n            pooled = torch.mean(outs, dim=1)\n\n        return self.fc(pooled)\n\n\ndef train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device, patience, min_delta, gradient_clip_value):\n    best_val_loss = float('inf')\n    epochs_no_improve = 0\n    best_model_state = None\n    history = {'train_loss': [], 'val_loss': []}\n\n    for epoch in range(num_epochs):\n        model.train()\n        running_train_loss = 0.0\n        for x_b, y_b in train_loader:\n            x_b, y_b = x_b.to(device), y_b.to(device)\n            optimizer.zero_grad()\n            preds = model(x_b)\n            loss = criterion(preds, y_b)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clip_value)\n            optimizer.step()\n            running_train_loss += loss.item() * x_b.size(0)\n        epoch_train_loss = running_train_loss / len(train_loader.dataset)\n        history['train_loss'].append(epoch_train_loss)\n\n        model.eval()\n        running_val_loss = 0.0\n        with torch.no_grad():\n            for x_val, y_val in val_loader:\n                x_val, y_val = x_val.to(device), y_val.to(device)\n                val_preds = model(x_val)\n                val_loss = criterion(val_preds, y_val)\n                running_val_loss += val_loss.item() * x_val.size(0)\n        epoch_val_loss = running_val_loss / len(val_loader.dataset)\n        history['val_loss'].append(epoch_val_loss)\n\n        print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {epoch_train_loss:.4f}, Val Loss: {epoch_val_loss:.4f}, LR: {optimizer.param_groups[0]['lr']:.2e}\")\n        scheduler.step(epoch_val_loss)\n\n        if epoch_val_loss < best_val_loss - min_delta:\n            best_val_loss = epoch_val_loss\n            epochs_no_improve = 0\n            best_model_state = model.state_dict()\n            print(f\"Validation loss improved to {best_val_loss:.4f}. Saving model state.\")\n        else:\n            epochs_no_improve += 1\n            print(f\"Validation loss did not improve for {epochs_no_improve} epoch(s).\")\n\n        if epochs_no_improve >= patience:\n            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n            break\n\n    if best_model_state:\n        model.load_state_dict(best_model_state)\n        print(\"Loaded best model state based on validation loss.\")\n    else:\n         print(\"No improvement meeting min_delta. Using model state from last epoch trained.\")\n\n\n    return model, history, best_val_loss\n\n\n\ndef evaluate_model(model, test_loader, criterion, device, components_list, target_means_train, target_stds_train):\n    model.eval()\n    preds_list, trues_list = [], []\n    test_loss = 0.0\n\n    with torch.no_grad():\n        for x_b, y_b_normalized in test_loader:\n            x_b, y_b_normalized = x_b.to(device), y_b_normalized.to(device)\n            p_normalized = model(x_b)\n            loss = criterion(p_normalized, y_b_normalized)\n            test_loss += loss.item() * x_b.size(0)\n            preds_list.append(p_normalized.cpu().numpy())\n            trues_list.append(y_b_normalized.cpu().numpy())\n\n    avg_test_loss = test_loss / len(test_loader.dataset)\n\n    preds_np_normalized = np.vstack(preds_list)\n    trues_np_normalized = np.vstack(trues_list)\n\n    preds_denorm = preds_np_normalized * target_stds_train + target_means_train\n    trues_denorm = trues_np_normalized * target_stds_train + target_means_train\n\n    mse_per_component = mean_squared_error(trues_denorm, preds_denorm, multioutput='raw_values')\n    mae_per_component = mean_absolute_error(trues_denorm, preds_denorm, multioutput='raw_values')\n    r2_per_component = r2_score(trues_denorm, preds_denorm, multioutput='raw_values')\n\n    metrics_df = pd.DataFrame({\n        'Component': components_list, 'MSE': mse_per_component,\n        'MAE': mae_per_component, 'R2': r2_per_component\n    })\n    return metrics_df, trues_denorm, preds_denorm\n\n\n\ndef run_single_config(config_entry, data_splits, target_norm_params, fixed_params):\n\n    config_name = config_entry.get('name', f'run_{id(config_entry)}')\n    config_params = config_entry.get('params', {})\n\n    print(f\"\\n--- Running Config: {config_name} ---\")\n    print(\"Parameters:\", config_params)\n\n\n  \n    seq_len = config_params.get('SEQ_LEN', 1000)\n    include_velocities = config_params.get('INCLUDE_VELOCITIES', True)\n    model_pooling_strategy = config_params.get('MODEL_POOLING_STRATEGY', 'last')\n    hidden_dim = config_params.get('HIDDEN_DIM', 256)\n    num_layers = config_params.get('NUM_LAYERS', 2)\n    # LSTM dropout is only applied if num_layers > 1\n    lstm_dropout = config_params.get('LSTM_DROPOUT', 0.3) if num_layers > 1 else 0.0\n    fc_dropout = config_params.get('FC_DROPOUT', 0.4)\n    optimizer_type = config_params.get('OPTIMIZER_TYPE', 'AdamW')\n    learning_rate = config_params.get('LEARNING_RATE', 1e-4)\n    batch_size = config_params.get('BATCH_SIZE', 16)\n    num_epochs = config_params.get('NUM_EPOCHS', 150)\n    weight_decay = config_params.get('WEIGHT_DECAY', 1e-4)\n    gradient_clip_value = config_params.get('GRADIENT_CLIP_VALUE', 1.0)\n    patience = config_params.get('PATIENCE', 15)\n    min_delta = config_params.get('MIN_DELTA', 0.0001)\n\n\n\n    npz_dir = fixed_params['NPZ_DIR']\n    device = fixed_params['DEVICE']\n    components_list = fixed_params['COMPONENTS_LIST']\n    output_dim = fixed_params['OUTPUT_DIM']\n    scaler_save_path_base = fixed_params['SCALER_SAVE_PATH_BASE']\n\n\n \n    scaler = fit_feature_scaler(data_splits['train_df_norm'], npz_dir, include_velocities)\n    current_scaler_save_path = f\"{scaler_save_path_base}_{config_name}.joblib\"\n    if scaler is not None:\n        try:\n            joblib.dump(scaler, current_scaler_save_path)\n            print(f\"Fitted scaler saved to {current_scaler_save_path}\")\n        except Exception as e:\n            print(f\"Warning: Could not save scaler for config {config_name}: {e}\")\n            current_scaler_save_path = None\n    else:\n        print(f\"Warning: Scaler could not be fitted for config {config_name}. Feature scaling will be skipped for this run.\")\n\n\n    \n    train_ds = SkeletonPCSDataset(data_splits['train_df_norm'], npz_dir, seq_len, components_list,\n                                  scaler=scaler, include_velocities=include_velocities)\n    val_ds   = SkeletonPCSDataset(data_splits['val_df_norm'],  npz_dir, seq_len, components_list,\n                                  scaler=scaler, include_velocities=include_velocities)\n    test_ds  = SkeletonPCSDataset(data_splits['test_df_norm'], npz_dir, seq_len, components_list,\n                                 scaler=scaler, include_velocities=include_velocities)\n\n    if len(train_ds) == 0 or len(val_ds) == 0 or len(test_ds) == 0:\n         print(f\"Skipping config {config_name}: One or more datasets are empty.\")\n         return {\n             'config_name': config_name,\n             'config_params': config_params,\n             'status': 'Skipped due to empty dataset',\n             'best_val_loss': float('inf'),\n             'test_metrics': None,\n             'history': None,\n             'model_state': None,\n             'scaler_path': None\n         }\n\n   \n    non_zero_samples = 0\n    for i in range(min(len(train_ds), 100)):\n        try:\n            x, _ = train_ds[i]\n            if torch.sum(x) != 0:\n                non_zero_samples += 1\n                break\n        except Exception as e:\n            print(f\"Warning: Error loading sample {i} for zero check: {e}\")\n            continue\n\n    if non_zero_samples == 0 and len(train_ds) > 0:\n         print(f\"Warning: First {min(len(train_ds), 100)} samples of training dataset for config {config_name} appear to be all zeros after loading/processing. Check NPZ files and path: {npz_dir}\")\n\n\n    actual_batch_size = min(batch_size, len(train_ds))\n    if actual_batch_size == 0:\n        print(f\"Skipping config {config_name}: Effective batch size is 0.\")\n        return {\n             'config_name': config_name, 'config_params': config_params,\n             'status': 'Skipped due to zero effective batch size',\n             'best_val_loss': float('inf'), 'test_metrics': None,\n             'history': None, 'model_state': None, 'scaler_path': None\n         }\n\n    train_loader = DataLoader(train_ds, batch_size=actual_batch_size, shuffle=True, num_workers=2, pin_memory=True, drop_last=True)\n    val_loader   = DataLoader(val_ds,   batch_size=min(batch_size, len(val_ds) or 1), shuffle=False, num_workers=2, pin_memory=True)\n    test_loader  = DataLoader(test_ds,  batch_size=min(batch_size, len(test_ds) or 1), shuffle=False, num_workers=2, pin_memory=True)\n\n\n    \n    input_dim = None\n    try:\n        for i in range(len(train_ds)):\n             sample_x_raw, _ = train_ds[i]\n             if torch.sum(sample_x_raw) != 0:\n                 input_dim = sample_x_raw.shape[1]\n                 break\n        if input_dim is None:\n             print(f\"CRITICAL ERROR: Could not determine input_dim from training dataset for config {config_name}. All samples seem to have failed loading/processing or are zeros.\")\n             return {\n                'config_name': config_name, 'config_params': config_params,\n                'status': 'Skipped due to input_dim determination failure',\n                'best_val_loss': float('inf'),\n                'test_metrics': None, 'history': None, 'model_state': None, 'scaler_path': None\n             }\n        print(f\"Determined input_dim for config {config_name}: {input_dim}\")\n\n    except Exception as e:\n        print(f\"CRITICAL ERROR: Could not determine input_dim for config {config_name}: {e}. Skipping config.\")\n        return {\n            'config_name': config_name, 'config_params': config_params,\n            'status': f'Skipped due to input_dim determination error: {e}',\n            'best_val_loss': float('inf'),\n            'test_metrics': None, 'history': None, 'model_state': None, 'scaler_path': None\n        }\n\n\n    model = LSTMRegressor(input_dim, hidden_dim, num_layers, output_dim,\n                          lstm_dropout, fc_dropout, model_pooling_strategy).to(device)\n    criterion = nn.SmoothL1Loss()\n\n    if optimizer_type.lower() == 'adamw':\n        optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n    else:\n        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n\n    current_scheduler_patience = max(1, patience // 2)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=current_scheduler_patience, verbose=True, min_lr=1e-7)\n\n    \n    print(f\"Starting training for config {config_name}...\")\n    try:\n        trained_model, history, best_val_loss_achieved = train_model(\n            model, train_loader, val_loader, criterion, optimizer, scheduler,\n            num_epochs, device, patience, min_delta, gradient_clip_value\n        )\n        status = 'Completed'\n        model_state_dict = trained_model.state_dict()\n\n        plt.figure(figsize=(10, 5))\n        plt.plot(history['train_loss'], label='Training Loss')\n        plt.plot(history['val_loss'], label='Validation Loss')\n        plt.title(f\"Config '{config_name}' Training and Validation Loss\")\n        plt.xlabel('Epochs'); plt.ylabel('Loss'); plt.legend(); plt.grid(True)\n        plt.savefig(f\"loss_plot_{config_name}.png\")\n        plt.close()\n\n    except Exception as e:\n        print(f\"Error during training for config {config_name}: {e}\")\n        status = f'Training failed: {e}'\n        best_val_loss_achieved = float('inf')\n        history = None\n        model_state_dict = None\n\n    \n    test_metrics = None\n    trues_denorm, preds_denorm = None, None\n    if status == 'Completed':\n        print(f\"Evaluating config {config_name} on the test set...\")\n        try:\n            test_metrics, trues_denorm, preds_denorm = evaluate_model(\n                trained_model, test_loader, criterion, device,\n                components_list, target_norm_params['target_means_train'], target_norm_params['target_stds_train']\n            )\n            print(f\"\\nTest Metrics for Config '{config_name}':\")\n            print(test_metrics)\n\n            for i, comp in enumerate(components_list):\n                plt.figure(figsize=(8, 8))\n                plt.scatter(trues_denorm[:, i], preds_denorm[:, i], alpha=0.6, edgecolors='w', linewidth=0.5)\n                min_val = min(trues_denorm[:, i].min(), preds_denorm[:, i].min()) - 0.5\n                max_val = max(trues_denorm[:, i].max(), preds_denorm[:, i].max()) + 0.5\n                plt.plot([min_val, max_val], [min_val, max_val], 'k--', lw=2, label='Ideal Fit (y=x)')\n                plt.xlabel(f\"True {comp}\"); plt.ylabel(f\"Predicted {comp}\")\n                r2_val = test_metrics.loc[test_metrics['Component'] == comp, 'R2'].values[0] if not test_metrics.empty else float('nan')\n                plt.title(f\"{comp}: True vs Predicted (Test Set, Config '{config_name}')\\nR2: {r2_val:.3f}\")\n                plt.legend(); plt.grid(True)\n                plt.savefig(f\"{comp}_true_vs_predicted_plot_{config_name}.png\");\n                plt.close()\n\n        except Exception as e:\n             print(f\"Error during evaluation for config {config_name}: {e}\")\n             status = f'Evaluation failed: {e}'\n             test_metrics = None\n\n    return {\n        'config_name': config_name,\n        'config_params': config_params,\n        'status': status,\n        'best_val_loss': best_val_loss_achieved,\n        'test_metrics': test_metrics.to_dict('records') if test_metrics is not None else None,\n        'history': history,\n        'model_state': model_state_dict,\n        'scaler_path': current_scaler_save_path,\n    }\n\n\n\nif __name__ == '__main__':\n    print(\"Starting hyperparameter tuning script...\")\n\n    \n    tuning_configuration_templates = user_tuning_configuration_templates\n    print(f\"Accessing tuning configurations from 'user_tuning_configuration_templates'.\")\n\n    \n    print(\"Expanding configuration templates...\")\n    expanded_tuning_configurations = expand_configurations(tuning_configuration_templates)\n    print(f\"Generated {len(expanded_tuning_configurations)} individual configurations to run.\")\n\n    if not expanded_tuning_configurations:\n        print(\"No configurations generated from templates. Exiting.\")\n        exit()\n\n\n    \n    \n    if 'df_components' not in locals():\n       print(\"INFO: 'df_components' not found. Creating a dummy DataFrame for demonstration.\")\n       num_unique_samples_demo = 150\n       sample_ids_repeated_demo = [f'sample_{i:03d}' for i in range(num_unique_samples_demo) for _ in range(len(COMPONENTS_LIST))]\n       components_repeated_demo = COMPONENTS_LIST * num_unique_samples_demo\n       panel_scores_demo = np.random.rand(num_unique_samples_demo * len(COMPONENTS_LIST)) * 7.5 + 2.5\n       df_components = pd.DataFrame({\n           'sample_id': sample_ids_repeated_demo, 'component': components_repeated_demo,\n           'panel_score': panel_scores_demo\n       })\n       print(f\"Created dummy df_components with {len(df_components)} rows.\")\n\n       if NPZ_DIR == '/kaggle/input/finefs/skeleton/skeleton':\n           print(\"INFO: NPZ_DIR is the placeholder. Creating dummy NPZ files.\")\n           dummy_npz_dir = \"dummy_npz_data_tuning_v5\" # Use a unique folder name\n           os.makedirs(dummy_npz_dir, exist_ok=True)\n           NPZ_DIR = dummy_npz_dir # Update NPZ_DIR for dummy data\n           print(f\"Updated NPZ_DIR to '{NPZ_DIR}'. Creating dummy NPZ files...\")\n           for i in range(num_unique_samples_demo):\n               dummy_skeleton_data = np.random.rand(np.random.randint(800,1201), 17, 3)\n               np.savez_compressed(os.path.join(NPZ_DIR, f'sample_{i:03d}.npz'), reconstruction=dummy_skeleton_data)\n           print(f\"Created {num_unique_samples_demo} dummy NPZ files in '{NPZ_DIR}'.\")\n\n\n    \n    pcs_df_unnormalized = (\n        df_components.loc[df_components['component'].isin(COMPONENTS_LIST)]\n        .pivot(index='sample_id', columns='component', values='panel_score')\n        .reset_index().rename_axis(None, axis=1)\n    )\n    pcs_df_unnormalized = pcs_df_unnormalized.dropna(subset=COMPONENTS_LIST)\n    if pcs_df_unnormalized.empty:\n        raise ValueError(\"pcs_df_unnormalized is empty after filtering and dropping NaNs. Check df_components and COMPONENTS_LIST.\")\n    print(f\"Created unnormalized PCS DataFrame with {len(pcs_df_unnormalized)} samples.\")\n\n    \n    train_val_df, test_df_unnorm = train_test_split(pcs_df_unnormalized, test_size=0.2, random_state=42)\n    train_df_unnorm, val_df_unnorm = train_test_split(train_val_df, test_size=0.15, random_state=42)\n\n    \n    target_means_train = train_df_unnorm[COMPONENTS_LIST].mean().values\n    target_stds_train = train_df_unnorm[COMPONENTS_LIST].std().values\n    target_stds_train[target_stds_train == 0] = 1.0\n\n    train_df_norm, val_df_norm, test_df_norm = train_df_unnorm.copy(), val_df_unnorm.copy(), test_df_unnorm.copy()\n    print(f\"Data splits (fixed for all runs): Train={len(train_df_norm)}, Val={len(val_df_norm)}, Test={len(test_df_norm)}\")\n    for i, col in enumerate(COMPONENTS_LIST):\n        train_df_norm[col] = (train_df_unnorm[col] - target_means_train[i]) / target_stds_train[i]\n        val_df_norm[col] = (val_df_unnorm[col] - target_means_train[i]) / target_stds_train[i]\n        test_df_norm[col] = (test_df_unnorm[col] - target_means_train[i]) / target_stds_train[i]\n\n    TARGET_NORM_PARAMS = {\n        'target_means_train': target_means_train,\n        'target_stds_train': target_stds_train\n    }\n\n    DATA_SPLITS = {\n        'train_df_norm': train_df_norm,\n        'val_df_norm': val_df_norm,\n        'test_df_norm': test_df_norm,\n    }\n\n    FIXED_PARAMS = {\n        'NPZ_DIR': NPZ_DIR,\n        'SCALER_SAVE_PATH_BASE': SCALER_SAVE_PATH_BASE,\n        'DEVICE': DEVICE,\n        'COMPONENTS_LIST': COMPONENTS_LIST,\n        'OUTPUT_DIM': OUTPUT_DIM,\n        'BEST_MODEL_PATH': BEST_MODEL_PATH, \n        'BEST_SCALER_PATH': BEST_SCALER_PATH,\n    }\n\n\n    \n    all_run_results = []\n    best_overall_val_loss = float('inf')\n    best_run_result = None\n\n    for config_entry in expanded_tuning_configurations:\n        run_result = run_single_config(\n            config_entry,\n            DATA_SPLITS,\n            TARGET_NORM_PARAMS,\n            FIXED_PARAMS\n        )\n        all_run_results.append(run_result)\n\n        if run_result['status'] == 'Completed' and run_result['best_val_loss'] < best_overall_val_loss:\n            best_overall_val_loss = run_result['best_val_loss']\n            best_run_result = run_result\n            print(f\"Config '{run_result['config_name']}' is the new best model with validation loss: {best_overall_val_loss:.4f}\")\n\n\n    \n    print(\"\\n--- Hyperparameter Tuning Results Summary ---\")\n\n    if not all_run_results:\n         print(\"No configurations were attempted.\")\n    else:\n        summary_data = []\n        for res in all_run_results:\n            summary_row = {'Config': res['config_name'], 'Status': res['status']}\n            if res['status'] == 'Completed':\n                summary_row['Best Val Loss'] = f\"{res['best_val_loss']:.4f}\"\n                if res['test_metrics']:\n                    avg_r2 = np.mean([m['R2'] for m in res['test_metrics']]) if res['test_metrics'] else float('nan')\n                    summary_row['Avg Test R2'] = f\"{avg_r2:.4f}\" if not np.isnan(avg_r2) else 'N/A'\n                else:\n                    summary_row['Avg Test R2'] = 'N/A'\n            else:\n                summary_row['Best Val Loss'] = 'N/A'\n                summary_row['Avg Test R2'] = 'N/A'\n\n            params = res.get('config_params', {})\n            \n           \n            summary_row['SeqLen'] = params.get('SEQ_LEN', 'N/A')\n            summary_row['HiddenDim'] = params.get('HIDDEN_DIM', 'N/A')\n            summary_row['Layers'] = params.get('NUM_LAYERS', 'N/A')\n            summary_row['LR'] = params.get('LEARNING_RATE', 'N/A')\n            summary_row['BatchSize'] = params.get('BATCH_SIZE', 'N/A')\n            summary_row['Patience'] = params.get('PATIENCE', 'N/A')\n            summary_row['FCDropout'] = params.get('FC_DROPOUT', 'N/A')\n\n            summary_data.append(summary_row)\n\n        if summary_data:\n            summary_df = pd.DataFrame(summary_data)\n            print(summary_df.to_string())\n\n\n        if best_run_result:\n            print(f\"\\n--- Overall Best Model: Config '{best_run_result['config_name']}' ---\")\n            print(\"Parameters:\")\n            for key, value in best_run_result.get('config_params', {}).items():\n                print(f\"  {key}: {value}\")\n\n            print(f\"Achieved Best Validation Loss during training: {best_run_result['best_val_loss']:.4f}\")\n\n            if best_run_result['test_metrics']:\n                print(\"\\nTest Set Metrics for the Best Model:\")\n                best_metrics_df = pd.DataFrame(best_run_result['test_metrics'])\n                print(best_metrics_df)\n            else:\n                 print(\"\\nTest set metrics not available for the best model (evaluation failed).\")\n\n            if best_run_result['model_state']:\n                try:\n                    torch.save(best_run_result['model_state'], FIXED_PARAMS['BEST_MODEL_PATH'])\n                    print(f\"\\nState dictionary of the best model saved to '{FIXED_PARAMS['BEST_MODEL_PATH']}'\")\n                except Exception as e:\n                    print(f\"Error saving best model state_dict to '{FIXED_PARAMS['BEST_MODEL_PATH']}': {e}\")\n            else:\n                 print(\"\\nBest model state dictionary is not available (training failed).\")\n\n\n            if best_run_result['scaler_path'] and os.path.exists(best_run_result['scaler_path']):\n                 try:\n                     best_scaler_dest_path = FIXED_PARAMS['BEST_SCALER_PATH']\n                     os.makedirs(os.path.dirname(best_scaler_dest_path) or '.', exist_ok=True)\n                     if os.path.abspath(best_run_result['scaler_path']) != os.path.abspath(best_scaler_dest_path):\n                        import shutil\n                        shutil.copyfile(best_run_result['scaler_path'], best_scaler_dest_path)\n                        print(f\"Scaler for the best model saved to '{best_scaler_dest_path}'\")\n                     else:\n                        print(f\"Scaler for the best model is already at the desired path '{best_scaler_dest_path}'\")\n\n                 except Exception as e:\n                     print(f\"Error saving best model's scaler to '{best_scaler_dest_path}': {e}\")\n            else:\n                 print(\"\\nWarning: Scaler for the best model was not found or not saved.\")\n\n        else:\n            print(\"\\nNo configuration completed successfully to determine a best model.\")\n\n    print(\"\\nScript finished.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T21:24:52.495004Z","iopub.execute_input":"2025-05-06T21:24:52.495406Z"}},"outputs":[{"name":"stdout","text":"Script is using device: cuda\nScript is using NPZ_DIR: /kaggle/input/finefs/skeleton/skeleton\nStarting hyperparameter tuning script...\nAccessing tuning configurations from 'user_tuning_configuration_templates'.\nExpanding configuration templates...\nGenerated 34 individual configurations to run.\nCreated unnormalized PCS DataFrame with 1167 samples.\nData splits (fixed for all runs): Train=793, Val=140, Test=234\n\n--- Running Config: lstm_lr_batch_wd_LEARNING_RATE0p0001_BATCH_SIZE16_WEIGHT_DECAY0p0_1 ---\nParameters: {'MODEL_TYPE': 'LSTM', 'SEQ_LEN': 1000, 'INCLUDE_VELOCITIES': True, 'INCLUDE_ACCELERATIONS': False, 'POSITION_ENCODING': 'absolute', 'MODEL_POOLING_STRATEGY': 'last', 'HIDDEN_DIM': 256, 'NUM_LAYERS': 2, 'LSTM_DROPOUT': 0.3, 'FC_DROPOUT': 0.4, 'OPTIMIZER_TYPE': 'AdamW', 'GRADIENT_CLIP_VALUE': 1.0, 'NUM_EPOCHS': 10, 'PATIENCE': 5, 'MIN_DELTA': 0.0001, 'LEARNING_RATE': 0.0001, 'BATCH_SIZE': 16, 'WEIGHT_DECAY': 0.0}\nCollecting data to fit the scaler...\nFitting scaler on 4017543 samples with 102 features each from 793 files.\nFitted scaler saved to lstm_feature_scaler_focused_lstm_lr_batch_wd_LEARNING_RATE0p0001_BATCH_SIZE16_WEIGHT_DECAY0p0_1.joblib\nDetermined input_dim for config lstm_lr_batch_wd_LEARNING_RATE0p0001_BATCH_SIZE16_WEIGHT_DECAY0p0_1: 102\nStarting training for config lstm_lr_batch_wd_LEARNING_RATE0p0001_BATCH_SIZE16_WEIGHT_DECAY0p0_1...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10 - Train Loss: 0.4327, Val Loss: 0.4268, LR: 1.00e-04\nValidation loss improved to 0.4268. Saving model state.\nEpoch 2/10 - Train Loss: 0.4320, Val Loss: 0.4274, LR: 1.00e-04\nValidation loss did not improve for 1 epoch(s).\nEpoch 3/10 - Train Loss: 0.4294, Val Loss: 0.4303, LR: 1.00e-04\nValidation loss did not improve for 2 epoch(s).\nEpoch 4/10 - Train Loss: 0.4242, Val Loss: 0.4357, LR: 1.00e-04\nValidation loss did not improve for 3 epoch(s).\nEpoch 5/10 - Train Loss: 0.4175, Val Loss: 0.4364, LR: 1.00e-05\nValidation loss did not improve for 4 epoch(s).\nEpoch 6/10 - Train Loss: 0.4174, Val Loss: 0.4375, LR: 1.00e-05\nValidation loss did not improve for 5 epoch(s).\nEarly stopping triggered after 6 epochs.\nLoaded best model state based on validation loss.\nEvaluating config lstm_lr_batch_wd_LEARNING_RATE0p0001_BATCH_SIZE16_WEIGHT_DECAY0p0_1 on the test set...\n\nTest Metrics for Config 'lstm_lr_batch_wd_LEARNING_RATE0p0001_BATCH_SIZE16_WEIGHT_DECAY0p0_1':\n        Component       MSE       MAE        R2\n0  skating_skills  1.137034  0.888651 -0.006368\n1     transitions  1.240844  0.923439 -0.004438\n2     performance  1.229753  0.922160 -0.006348\n3     composition  1.203282  0.912380 -0.007088\n4  interpretation  1.229383  0.917555 -0.007669\nConfig 'lstm_lr_batch_wd_LEARNING_RATE0p0001_BATCH_SIZE16_WEIGHT_DECAY0p0_1' is the new best model with validation loss: 0.4268\n\n--- Running Config: lstm_lr_batch_wd_LEARNING_RATE0p0001_BATCH_SIZE16_WEIGHT_DECAY0p000..._2 ---\nParameters: {'MODEL_TYPE': 'LSTM', 'SEQ_LEN': 1000, 'INCLUDE_VELOCITIES': True, 'INCLUDE_ACCELERATIONS': False, 'POSITION_ENCODING': 'absolute', 'MODEL_POOLING_STRATEGY': 'last', 'HIDDEN_DIM': 256, 'NUM_LAYERS': 2, 'LSTM_DROPOUT': 0.3, 'FC_DROPOUT': 0.4, 'OPTIMIZER_TYPE': 'AdamW', 'GRADIENT_CLIP_VALUE': 1.0, 'NUM_EPOCHS': 10, 'PATIENCE': 5, 'MIN_DELTA': 0.0001, 'LEARNING_RATE': 0.0001, 'BATCH_SIZE': 16, 'WEIGHT_DECAY': 0.0001}\nCollecting data to fit the scaler...\nFitting scaler on 4017543 samples with 102 features each from 793 files.\nFitted scaler saved to lstm_feature_scaler_focused_lstm_lr_batch_wd_LEARNING_RATE0p0001_BATCH_SIZE16_WEIGHT_DECAY0p000..._2.joblib\nDetermined input_dim for config lstm_lr_batch_wd_LEARNING_RATE0p0001_BATCH_SIZE16_WEIGHT_DECAY0p000..._2: 102\nStarting training for config lstm_lr_batch_wd_LEARNING_RATE0p0001_BATCH_SIZE16_WEIGHT_DECAY0p000..._2...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10 - Train Loss: 0.4331, Val Loss: 0.4265, LR: 1.00e-04\nValidation loss improved to 0.4265. Saving model state.\nEpoch 2/10 - Train Loss: 0.4322, Val Loss: 0.4271, LR: 1.00e-04\nValidation loss did not improve for 1 epoch(s).\nEpoch 3/10 - Train Loss: 0.4288, Val Loss: 0.4322, LR: 1.00e-04\nValidation loss did not improve for 2 epoch(s).\nEpoch 4/10 - Train Loss: 0.4202, Val Loss: 0.4436, LR: 1.00e-04\nValidation loss did not improve for 3 epoch(s).\nEpoch 5/10 - Train Loss: 0.4153, Val Loss: 0.4424, LR: 1.00e-05\nValidation loss did not improve for 4 epoch(s).\nEpoch 6/10 - Train Loss: 0.4124, Val Loss: 0.4426, LR: 1.00e-05\nValidation loss did not improve for 5 epoch(s).\nEarly stopping triggered after 6 epochs.\nLoaded best model state based on validation loss.\nEvaluating config lstm_lr_batch_wd_LEARNING_RATE0p0001_BATCH_SIZE16_WEIGHT_DECAY0p000..._2 on the test set...\n\nTest Metrics for Config 'lstm_lr_batch_wd_LEARNING_RATE0p0001_BATCH_SIZE16_WEIGHT_DECAY0p000..._2':\n        Component       MSE       MAE        R2\n0  skating_skills  1.151773  0.892302 -0.019413\n1     transitions  1.248548  0.921844 -0.010674\n2     performance  1.234432  0.922366 -0.010177\n3     composition  1.207457  0.912858 -0.010582\n4  interpretation  1.232579  0.916659 -0.010289\nConfig 'lstm_lr_batch_wd_LEARNING_RATE0p0001_BATCH_SIZE16_WEIGHT_DECAY0p000..._2' is the new best model with validation loss: 0.4265\n\n--- Running Config: lstm_lr_batch_wd_LEARNING_RATE0p0001_BATCH_SIZE16_WEIGHT_DECAY1em05_3 ---\nParameters: {'MODEL_TYPE': 'LSTM', 'SEQ_LEN': 1000, 'INCLUDE_VELOCITIES': True, 'INCLUDE_ACCELERATIONS': False, 'POSITION_ENCODING': 'absolute', 'MODEL_POOLING_STRATEGY': 'last', 'HIDDEN_DIM': 256, 'NUM_LAYERS': 2, 'LSTM_DROPOUT': 0.3, 'FC_DROPOUT': 0.4, 'OPTIMIZER_TYPE': 'AdamW', 'GRADIENT_CLIP_VALUE': 1.0, 'NUM_EPOCHS': 10, 'PATIENCE': 5, 'MIN_DELTA': 0.0001, 'LEARNING_RATE': 0.0001, 'BATCH_SIZE': 16, 'WEIGHT_DECAY': 1e-05}\nCollecting data to fit the scaler...\nFitting scaler on 4017543 samples with 102 features each from 793 files.\nFitted scaler saved to lstm_feature_scaler_focused_lstm_lr_batch_wd_LEARNING_RATE0p0001_BATCH_SIZE16_WEIGHT_DECAY1em05_3.joblib\nDetermined input_dim for config lstm_lr_batch_wd_LEARNING_RATE0p0001_BATCH_SIZE16_WEIGHT_DECAY1em05_3: 102\nStarting training for config lstm_lr_batch_wd_LEARNING_RATE0p0001_BATCH_SIZE16_WEIGHT_DECAY1em05_3...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10 - Train Loss: 0.4348, Val Loss: 0.4291, LR: 1.00e-04\nValidation loss improved to 0.4291. Saving model state.\nEpoch 2/10 - Train Loss: 0.4330, Val Loss: 0.4280, LR: 1.00e-04\nValidation loss improved to 0.4280. Saving model state.\nEpoch 3/10 - Train Loss: 0.4308, Val Loss: 0.4299, LR: 1.00e-04\nValidation loss did not improve for 1 epoch(s).\nEpoch 4/10 - Train Loss: 0.4252, Val Loss: 0.4316, LR: 1.00e-04\nValidation loss did not improve for 2 epoch(s).\nEpoch 5/10 - Train Loss: 0.4220, Val Loss: 0.4464, LR: 1.00e-04\nValidation loss did not improve for 3 epoch(s).\nEpoch 6/10 - Train Loss: 0.4149, Val Loss: 0.4440, LR: 1.00e-05\nValidation loss did not improve for 4 epoch(s).\nEpoch 7/10 - Train Loss: 0.4153, Val Loss: 0.4442, LR: 1.00e-05\nValidation loss did not improve for 5 epoch(s).\nEarly stopping triggered after 7 epochs.\nLoaded best model state based on validation loss.\nEvaluating config lstm_lr_batch_wd_LEARNING_RATE0p0001_BATCH_SIZE16_WEIGHT_DECAY1em05_3 on the test set...\n\nTest Metrics for Config 'lstm_lr_batch_wd_LEARNING_RATE0p0001_BATCH_SIZE16_WEIGHT_DECAY1em05_3':\n        Component       MSE       MAE        R2\n0  skating_skills  1.147590  0.893932 -0.015711\n1     transitions  1.238981  0.923293 -0.002929\n2     performance  1.248290  0.930876 -0.021517\n3     composition  1.205582  0.913440 -0.009013\n4  interpretation  1.239287  0.921615 -0.015787\n\n--- Running Config: lstm_lr_batch_wd_LEARNING_RATE0p0001_BATCH_SIZE32_WEIGHT_DECAY0p0_4 ---\nParameters: {'MODEL_TYPE': 'LSTM', 'SEQ_LEN': 1000, 'INCLUDE_VELOCITIES': True, 'INCLUDE_ACCELERATIONS': False, 'POSITION_ENCODING': 'absolute', 'MODEL_POOLING_STRATEGY': 'last', 'HIDDEN_DIM': 256, 'NUM_LAYERS': 2, 'LSTM_DROPOUT': 0.3, 'FC_DROPOUT': 0.4, 'OPTIMIZER_TYPE': 'AdamW', 'GRADIENT_CLIP_VALUE': 1.0, 'NUM_EPOCHS': 10, 'PATIENCE': 5, 'MIN_DELTA': 0.0001, 'LEARNING_RATE': 0.0001, 'BATCH_SIZE': 32, 'WEIGHT_DECAY': 0.0}\nCollecting data to fit the scaler...\nFitting scaler on 4017543 samples with 102 features each from 793 files.\nFitted scaler saved to lstm_feature_scaler_focused_lstm_lr_batch_wd_LEARNING_RATE0p0001_BATCH_SIZE32_WEIGHT_DECAY0p0_4.joblib\nDetermined input_dim for config lstm_lr_batch_wd_LEARNING_RATE0p0001_BATCH_SIZE32_WEIGHT_DECAY0p0_4: 102\nStarting training for config lstm_lr_batch_wd_LEARNING_RATE0p0001_BATCH_SIZE32_WEIGHT_DECAY0p0_4...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10 - Train Loss: 0.4234, Val Loss: 0.4296, LR: 1.00e-04\nValidation loss improved to 0.4296. Saving model state.\nEpoch 2/10 - Train Loss: 0.4253, Val Loss: 0.4294, LR: 1.00e-04\nValidation loss improved to 0.4294. Saving model state.\nEpoch 3/10 - Train Loss: 0.4239, Val Loss: 0.4296, LR: 1.00e-04\nValidation loss did not improve for 1 epoch(s).\nEpoch 4/10 - Train Loss: 0.4182, Val Loss: 0.4318, LR: 1.00e-04\nValidation loss did not improve for 2 epoch(s).\nEpoch 5/10 - Train Loss: 0.4103, Val Loss: 0.4404, LR: 1.00e-04\nValidation loss did not improve for 3 epoch(s).\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"\nclass SkeletonPCSDataset(Dataset):\n    def __init__(self, manifest_df, npz_dir, seq_len=6000):\n        self.df = manifest_df\n        self.npz_dir = npz_dir\n        self.seq_len = seq_len\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        data = np.load(os.path.join(self.npz_dir, row['sample_id']+'.npz'))['reconstruction']\n        T, J, C = data.shape\n        x = data.reshape(T, J*C).astype(np.float32)\n        if T < self.seq_len:\n            pad = np.zeros((self.seq_len - T, J*C), dtype=np.float32)\n            x = np.vstack([x, pad])\n        else:\n            x = x[:self.seq_len]\n        y = np.array([\n            row['skating_skills'], row['transitions'],\n            row['performance'], row['composition'],\n            row['interpretation']\n        ], dtype=np.float32)\n        return torch.from_numpy(x), torch.from_numpy(y)\n\n\ntrain_df, test_df = train_test_split(pcs_df, test_size=0.2, random_state=42)\ntrain_ds = SkeletonPCSDataset(train_df, NPZ_DIR, seq_len=1000)\ntest_ds  = SkeletonPCSDataset(test_df,  NPZ_DIR, seq_len=1000)\n\n\ntrain_loader = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=4, pin_memory=True)\ntest_loader  = DataLoader(test_ds,  batch_size=16, shuffle=False, num_workers=4, pin_memory=True)\n\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nsample_x, _ = train_ds[0]\ninput_dim = sample_x.shape[1]\n\n\nclass LSTMRegressor(nn.Module):\n    def __init__(self, input_dim, hidden_dim=256, num_layers=3, output_dim=5, dropout=0.5):\n        super().__init__()\n        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers,\n                            batch_first=True, bidirectional=True, dropout=dropout)\n        self.fc = nn.Sequential(\n            nn.Linear(hidden_dim * 2, 128),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(128, output_dim)\n        )\n    def forward(self, x):\n        outs, _ = self.lstm(x)\n        pooled = torch.mean(outs, dim=1)\n        return self.fc(pooled)\n\n        \n        \nmodel = LSTMRegressor(input_dim, hidden_dim=128, num_layers=2, output_dim=5).to(device)\n\ncriterion = torch.nn.SmoothL1Loss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n\nfor epoch in range(20):\n    model.train()\n    for x_b, y_b in train_loader:\n        x_b, y_b = x_b.to(device), y_b.to(device)\n        optimizer.zero_grad()\n        loss = criterion(model(x_b), y_b)\n        loss.backward()\n        optimizer.step()\n    print(f\"Epoch {epoch+1} complete\")\n\n\nmodel.eval()\npreds, trues = [], []\nwith torch.no_grad():\n    for x_b, y_b in test_loader:\n        x_b = x_b.to(device)\n        p = model(x_b).cpu().numpy()\n        preds.append(p)\n        trues.append(y_b.numpy())\npreds = np.vstack(preds)\ntarget = np.vstack(trues)\n\n\npreds = preds * target_stds.values + target_means.values\ntarget = target * target_stds.values + target_means.values\n\n\ncomponents = ['skating_skills','transitions','performance','composition','interpretation']\nmse = mean_squared_error(target, preds, multioutput='raw_values')\nmae = mean_absolute_error(target, preds, multioutput='raw_values')\nmetrics = pd.DataFrame({'Component': components, 'MSE': mse, 'MAE': mae})\nprint(metrics)\n\n\nfor i, comp in enumerate(components):\n    plt.figure()\n    plt.scatter(target[:, i], preds[:, i], alpha=0.5)\n    plt.xlabel(f\"True {comp}\")\n    plt.ylabel(f\"Predicted {comp}\")\n    plt.title(f\"{comp}: True vs Predicted\")\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nimport matplotlib.pyplot as plt\n\n\n# Paths and Data\nNPZ_DIR = 'path/to/your/npz_files' \nMANIFEST_FILE = 'path/to/your/manifest.csv' \n\n\nSEQ_LEN = 1000         \nHIDDEN_DIM = 256       \nNUM_LAYERS = 3         \nDROPOUT = 0.5          \nOUTPUT_DIM = 5         \n\n\nLEARNING_RATE = 1e-4   \nBATCH_SIZE = 16        \nNUM_EPOCHS = 100       \nWEIGHT_DECAY = 1e-5    \nGRADIENT_CLIP_VALUE = 1.0 \n\n# Early Stopping\nPATIENCE = 10          \nMIN_DELTA = 0.0001     \n\n\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {DEVICE}\")\n\n\nclass SkeletonPCSDataset(Dataset):\n    def __init__(self, manifest_df, npz_dir, seq_len, include_velocities=True):\n        self.df = manifest_df\n        self.npz_dir = npz_dir\n        self.seq_len = seq_len\n        self.include_velocities = include_velocities\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        # Ensure sample_id is a string and doesn't already have .npz\n        sample_id_str = str(row['sample_id']).replace('.npz', '')\n        file_path = os.path.join(self.npz_dir, sample_id_str + '.npz')\n\n        try:\n            data = np.load(file_path)['reconstruction'] \n        except FileNotFoundError:\n            print(f\"Error: File not found {file_path}\")\n            \n            dummy_features = 17*3 \n            if self.include_velocities:\n                dummy_features *= 2\n            return torch.zeros(self.seq_len, dummy_features), torch.zeros(OUTPUT_DIM)\n        except KeyError:\n            print(f\"Error: 'reconstruction' key not found in {file_path}\")\n            dummy_features = 17*3\n            if self.include_velocities:\n                dummy_features *= 2\n            return torch.zeros(self.seq_len, dummy_features), torch.zeros(OUTPUT_DIM)\n\n\n        T, J, C = data.shape \n        x_coords = data.reshape(T, J * C).astype(np.float32)\n\n        if self.include_velocities:\n            if T > 1:\n                velocities = np.diff(x_coords, axis=0)\n                \n                velocities = np.vstack([np.zeros((1, J * C), dtype=np.float32), velocities])\n            else: \n                velocities = np.zeros_like(x_coords, dtype=np.float32)\n            \n            x_combined = np.concatenate([x_coords, velocities], axis=1)\n        else:\n            x_combined = x_coords\n\n        current_T, current_features_dim = x_combined.shape\n\n        \n        if current_T < self.seq_len:\n            pad = np.zeros((self.seq_len - current_T, current_features_dim), dtype=np.float32)\n            x_processed = np.vstack([x_combined, pad])\n        else:\n            x_processed = x_combined[:self.seq_len]\n\n        y = np.array([\n            row['skating_skills'], row['transitions'],\n            row['performance'], row['composition'],\n            row['interpretation']\n        ], dtype=np.float32)\n\n        return torch.from_numpy(x_processed), torch.from_numpy(y)\n\n\nclass LSTMRegressor(nn.Module):\n    def __init__(self, input_dim, hidden_dim, num_layers, output_dim, dropout):\n        super().__init__()\n        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers,\n                              batch_first=True, bidirectional=True, dropout=dropout if num_layers > 1 else 0)\n        self.fc = nn.Sequential(\n            nn.Linear(hidden_dim * 2, hidden_dim), # *2 for bidirectional\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, 128),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(128, output_dim)\n        )\n\n    def forward(self, x):\n        \n        outs, _ = self.lstm(x)\n       \n        \n       \n        pooled = torch.mean(outs, dim=1)\n       \n        \n        return self.fc(pooled)\n\n\ndef train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device, patience, min_delta, gradient_clip_value):\n    best_val_loss = float('inf')\n    epochs_no_improve = 0\n    best_model_state = None\n    history = {'train_loss': [], 'val_loss': []}\n\n    for epoch in range(num_epochs):\n        model.train()\n        running_train_loss = 0.0\n        for x_b, y_b in train_loader:\n            x_b, y_b = x_b.to(device), y_b.to(device)\n            \n            optimizer.zero_grad()\n            preds = model(x_b)\n            loss = criterion(preds, y_b)\n            loss.backward()\n            \n            # Gradient Clipping\n            torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clip_value)\n            \n            optimizer.step()\n            running_train_loss += loss.item() * x_b.size(0)\n\n        epoch_train_loss = running_train_loss / len(train_loader.dataset)\n        history['train_loss'].append(epoch_train_loss)\n\n        # Validation phase\n        model.eval()\n        running_val_loss = 0.0\n        with torch.no_grad():\n            for x_val, y_val in val_loader:\n                x_val, y_val = x_val.to(device), y_val.to(device)\n                val_preds = model(x_val)\n                val_loss = criterion(val_preds, y_val)\n                running_val_loss += val_loss.item() * x_val.size(0)\n        \n        epoch_val_loss = running_val_loss / len(val_loader.dataset)\n        history['val_loss'].append(epoch_val_loss)\n\n        print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {epoch_train_loss:.4f}, Val Loss: {epoch_val_loss:.4f}\")\n\n       \n        scheduler.step(epoch_val_loss)\n\n        \n        if epoch_val_loss < best_val_loss - min_delta:\n            best_val_loss = epoch_val_loss\n            epochs_no_improve = 0\n            best_model_state = model.state_dict() \n            print(f\"Validation loss improved. Saving model state.\")\n        else:\n            epochs_no_improve += 1\n            print(f\"Validation loss did not improve for {epochs_no_improve} epoch(s).\")\n\n        if epochs_no_improve >= patience:\n            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n            if best_model_state:\n                model.load_state_dict(best_model_state) \n            break\n            \n    if best_model_state and epochs_no_improve < patience : # if training finished before early stopping\n        print(\"Training finished. Restoring best model state based on validation loss.\")\n        model.load_state_dict(best_model_state)\n\n    return model, history\n\n\ndef evaluate_model(model, test_loader, criterion, device, target_means, target_stds, components):\n    model.eval()\n    preds_list, trues_list = [], []\n    test_loss = 0.0\n\n    with torch.no_grad():\n        for x_b, y_b in test_loader:\n            x_b, y_b_cpu = x_b.to(device), y_b \n            \n            p = model(x_b)\n            loss = criterion(p, y_b_cpu.to(device)) \n            test_loss += loss.item() * x_b.size(0)\n            \n            preds_list.append(p.cpu().numpy())\n            trues_list.append(y_b_cpu.numpy())\n\n    avg_test_loss = test_loss / len(test_loader.dataset)\n    print(f\"Average Test Loss: {avg_test_loss:.4f}\")\n\n    preds_np = np.vstack(preds_list)\n    trues_np = np.vstack(trues_list)\n\n    \n    if isinstance(target_means, pd.Series): target_means = target_means.values\n    if isinstance(target_stds, pd.Series): target_stds = target_stds.values\n    \n    preds_denorm = preds_np * target_stds + target_means\n    trues_denorm = trues_np * target_stds + target_means\n    \n    mse_per_component = mean_squared_error(trues_denorm, preds_denorm, multioutput='raw_values')\n    mae_per_component = mean_absolute_error(trues_denorm, preds_denorm, multioutput='raw_values')\n    r2_per_component = r2_score(trues_denorm, preds_denorm, multioutput='raw_values')\n    \n    metrics_df = pd.DataFrame({\n        'Component': components,\n        'MSE': mse_per_component,\n        'MAE': mae_per_component,\n        'R2': r2_per_component\n    })\n    \n    return metrics_df, trues_denorm, preds_denorm\n\n\nif __name__ == '__main__':\n    \n    try:\n        pcs_df = pd.read_csv(MANIFEST_FILE)\n        # Example: Assuming 'sample_id' column exists and other score columns\n        if not all(col in pcs_df.columns for col in ['sample_id', 'skating_skills','transitions','performance','composition','interpretation']):\n            raise ValueError(\"Manifest CSV missing required columns.\")\n    except FileNotFoundError:\n        print(f\"Error: Manifest file '{MANIFEST_FILE}' not found. Using dummy data for demonstration.\")\n        # Create a dummy pcs_df for demonstration if the file is not found\n        num_samples = 100\n        dummy_data = {\n            'sample_id': [f'sample_{i:03d}' for i in range(num_samples)],\n            'skating_skills': np.random.rand(num_samples) * 10,\n            'transitions': np.random.rand(num_samples) * 10,\n            'performance': np.random.rand(num_samples) * 10,\n            'composition': np.random.rand(num_samples) * 10,\n            'interpretation': np.random.rand(num_samples) * 10\n        }\n        pcs_df = pd.DataFrame(dummy_data)\n        \n        \n        if NPZ_DIR == 'path/to/your/npz_files':\n            print(\"NPZ_DIR is a placeholder. Creating dummy NPZ files for demonstration.\")\n            os.makedirs(\"dummy_npz_data\", exist_ok=True)\n            NPZ_DIR = \"dummy_npz_data\"\n            for i in range(num_samples):\n                # (Time, Joints, Coords) e.g., (random_time, 17 joints, 3 coords)\n                # Time steps between 500 and 1500 for variety\n                dummy_skeleton_data = np.random.rand(np.random.randint(500,1501), 17, 3)\n                np.savez_compressed(os.path.join(NPZ_DIR, f'sample_{i:03d}.npz'), reconstruction=dummy_skeleton_data)\n            print(f\"Created dummy NPZ files in '{NPZ_DIR}'.\")\n\n\n    components = ['skating_skills','transitions','performance','composition','interpretation']\n    \n   \n    train_val_df, test_df = train_test_split(pcs_df, test_size=0.2, random_state=42)\n    train_df, val_df = train_test_split(train_val_df, test_size=0.15, random_state=42) # 0.15 * 0.8 = 0.12 of total\n\n    print(f\"Training samples: {len(train_df)}\")\n    print(f\"Validation samples: {len(val_df)}\")\n    print(f\"Test samples: {len(test_df)}\")\n\n    \n    target_means_train = train_df[components].mean().values\n    target_stds_train = train_df[components].std().values\n    \n    target_stds_train[target_stds_train == 0] = 1.0 \n\n    \n\n    \n    include_velocities_feature = True \n    \n    train_ds = SkeletonPCSDataset(train_df, NPZ_DIR, SEQ_LEN, include_velocities=include_velocities_feature)\n    val_ds = SkeletonPCSDataset(val_df, NPZ_DIR, SEQ_LEN, include_velocities=include_velocities_feature)\n    test_ds  = SkeletonPCSDataset(test_df,  NPZ_DIR, SEQ_LEN, include_velocities=include_velocities_feature)\n\n    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True, drop_last=True) # num_workers can be os.cpu_count()\n    val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n    test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n\n   \n    try:\n        sample_x_raw, _ = train_ds[0] # This will be (seq_len, features_dim)\n        input_dim = sample_x_raw.shape[1]\n    except Exception as e:\n        print(f\"Could not determine input_dim from dataset sample: {e}. Defaulting.\")\n        \n        num_joints_coords = 17 * 3 \n        input_dim = num_joints_coords * 2 if include_velocities_feature else num_joints_coords\n        print(f\"Defaulted input_dim to: {input_dim} (assuming 17 joints, 3 coords, velocities={include_velocities_feature})\")\n\n\n    print(f\"Model input_dim: {input_dim}\")\n    \n    model = LSTMRegressor(input_dim, HIDDEN_DIM, NUM_LAYERS, OUTPUT_DIM, DROPOUT).to(DEVICE)\n    criterion = nn.SmoothL1Loss() # Or nn.MSELoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=PATIENCE//2, verbose=True)\n\n    \n    print(\"Starting training...\")\n    model, history = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, NUM_EPOCHS, DEVICE, PATIENCE, MIN_DELTA, GRADIENT_CLIP_VALUE)\n    \n    \n    plt.figure(figsize=(10, 5))\n    plt.plot(history['train_loss'], label='Training Loss')\n    plt.plot(history['val_loss'], label='Validation Loss')\n    plt.title('Training and Validation Loss Over Epochs')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\n    \n    print(\"\\nEvaluating on the test set...\")\n    metrics_df, trues_denorm, preds_denorm = evaluate_model(model, test_loader, criterion, DEVICE, target_means_train, target_stds_train, components)\n    print(\"\\nTest Set Metrics:\")\n    print(metrics_df)\n\n    \n    for i, comp in enumerate(components):\n        plt.figure(figsize=(8, 8))\n        plt.scatter(trues_denorm[:, i], preds_denorm[:, i], alpha=0.6, edgecolors='w', linewidth=0.5)\n        # Add a y=x line for reference\n        min_val = min(trues_denorm[:, i].min(), preds_denorm[:, i].min())\n        max_val = max(trues_denorm[:, i].max(), preds_denorm[:, i].max())\n        plt.plot([min_val, max_val], [min_val, max_val], 'k--', lw=2, label='Ideal Fit (y=x)')\n        plt.xlabel(f\"True {comp}\")\n        plt.ylabel(f\"Predicted {comp}\")\n        plt.title(f\"{comp}: True vs Predicted (Test Set)\\nR2: {metrics_df.loc[metrics_df['Component'] == comp, 'R2'].values[0]:.3f}\")\n        plt.legend()\n        plt.grid(True)\n        plt.show()\n\n    print(\"\\nScript finished.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom scipy.stats import spearmanr\nimport torch\nimport pandas as pd\n\n\ndef pearson_per_dim(y_true, y_pred):\n    r_vals = []\n    for i in range(y_true.shape[1]):\n        r = np.corrcoef(y_true[:, i], y_pred[:, i])[0, 1]\n        r_vals.append(r)\n    return np.array(r_vals)\n\n\ndef concordance_cc(y_true, y_pred):\n    cc_vals = []\n    for i in range(y_true.shape[1]):\n        t = y_true[:, i]\n        p = y_pred[:, i]\n        cov = np.mean((t - t.mean()) * (p - p.mean()))\n        cc = 2 * cov / (t.var() + p.var() + (t.mean() - p.mean())**2 + 1e-8)\n        cc_vals.append(cc)\n    return np.array(cc_vals)\n\n\nmodel.eval()\ny_true = []\ny_pred = []\n\nwith torch.no_grad():\n    for x_batch, y_batch in test_loader:\n        x_batch = x_batch.to(device)\n        preds = model(x_batch)\n        y_true.append(y_batch.numpy())\n        y_pred.append(preds.cpu().numpy())\n\ny_true = np.vstack(y_true)\ny_pred = np.vstack(y_pred)\n\n\ny_true = y_true * target_stds.values + target_means.values\ny_pred = y_pred * target_stds.values + target_means.values\n\n\ncomponents = ['skating_skills', 'transitions', 'performance', 'composition', 'interpretation']\n\nmse = mean_squared_error(y_true, y_pred, multioutput='raw_values')\nmae = mean_absolute_error(y_true, y_pred, multioutput='raw_values')\nr2 = r2_score(y_true, y_pred, multioutput='raw_values')\npearson = pearson_per_dim(y_true, y_pred)\nspearman = np.array([spearmanr(y_true[:, i], y_pred[:, i])[0] for i in range(y_true.shape[1])])\nccc = concordance_cc(y_true, y_pred)\n\nmetrics_df = pd.DataFrame({\n    'Component': components,\n    'MSE': mse,\n    'MAE': mae,\n    'R2': r2,\n    'Pearson': pearson,\n    'Spearman': spearman,\n    'CCC': ccc\n})\nprint(metrics_df.round(4))\n\n\nsns.set(style=\"whitegrid\")\n\n\nfig, axes = plt.subplots(2, 3, figsize=(18, 10))\naxes = axes.flatten()\nfor i, name in enumerate(components):\n    ax = axes[i]\n    ax.scatter(y_true[:, i], y_pred[:, i], alpha=0.5)\n    ax.plot([0, 10], [0, 10], 'r--')\n    ax.set_title(f'{name} (R={r2[i]:.2f}, r={pearson[i]:.2f})')\n    ax.set_xlabel('True')\n    ax.set_ylabel('Predicted')\n    ax.set_xlim(0, 10)\n    ax.set_ylim(0, 10)\nfig.suptitle('True vs. Predicted Scores')\nplt.tight_layout()\nplt.show()\n\n\nfig, axes = plt.subplots(2, 3, figsize=(18, 10))\naxes = axes.flatten()\nfor i, name in enumerate(components):\n    ax = axes[i]\n    avg = (y_true[:, i] + y_pred[:, i]) / 2\n    diff = y_pred[:, i] - y_true[:, i]\n    mean_diff = np.mean(diff)\n    std_diff = np.std(diff)\n    ax.scatter(avg, diff, alpha=0.5)\n    ax.axhline(mean_diff, color='gray', linestyle='--')\n    ax.axhline(mean_diff + 1.96 * std_diff, color='red', linestyle='--')\n    ax.axhline(mean_diff - 1.96 * std_diff, color='red', linestyle='--')\n    ax.set_title(f'{name} BlandAltman')\n    ax.set_xlabel('Mean of True & Predicted')\n    ax.set_ylabel('Prediction Error')\nfig.suptitle('BlandAltman Plots')\nplt.tight_layout()\nplt.show()\n\n\nfig, axes = plt.subplots(2, 3, figsize=(18, 10))\naxes = axes.flatten()\nfor i, name in enumerate(components):\n    residuals = y_pred[:, i] - y_true[:, i]\n    sns.histplot(residuals, bins=30, kde=True, ax=axes[i])\n    axes[i].set_title(f'{name} Residuals')\n    axes[i].set_xlabel('Prediction Error')\nfig.suptitle('Residual Histograms')\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\nimport matplotlib.pyplot as plt\n\n# --- Dataset ---\nclass SkeletonPCSDataset(Dataset):\n    def __init__(self, manifest_df, npz_dir, seq_len=1000):\n        self.df = manifest_df\n        self.npz_dir = npz_dir\n        self.seq_len = seq_len\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        sample_id = row['sample_id']\n        npz_file = os.path.join(self.npz_dir, sample_id + '.npz')\n        data = np.load(npz_file)['reconstruction']\n        T, J, C = data.shape\n        x = data.reshape(T, J*C).astype(np.float32)\n\n        # Normalize input sequence (per sample)\n        x = (x - np.mean(x, axis=0)) / (np.std(x, axis=0) + 1e-6)\n\n        if T < self.seq_len:\n            pad = np.zeros((self.seq_len - T, J*C), dtype=np.float32)\n            x = np.vstack([x, pad])\n        else:\n            x = x[:self.seq_len]\n\n        y = np.array([\n            row['skating_skills'],\n            row['transitions'],\n            row['performance'],\n            row['composition'],\n            row['interpretation']\n        ], dtype=np.float32)\n\n        return torch.from_numpy(x), torch.from_numpy(y)\n\n\nclass LSTMRegressor(nn.Module):\n    def __init__(self, input_dim, hidden_dim=256, num_layers=2, output_dim=5, dropout=0.3):\n        super().__init__()\n        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers,\n                            batch_first=True, bidirectional=True, dropout=dropout)\n        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n\n    def forward(self, x):\n        outs, _ = self.lstm(x)\n        final = outs[:, -1, :]\n        \n        return self.fc(final)\n\n\nNPZ_DIR = '/kaggle/input/finefs/skeleton/skeleton'\nSEQ_LEN = 500\ndataset = SkeletonPCSDataset(pcs_df, NPZ_DIR, seq_len=SEQ_LEN)\n\n\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2, pin_memory=True)\nval_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=2, pin_memory=True)\n\n\nsample_x, _ = dataset[0]\ninput_dim = sample_x.shape[1]\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nmodel = LSTMRegressor(input_dim).to(device)\n\ncriterion = torch.nn.SmoothL1Loss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n\n\nfor epoch in range(10):\n    model.train()\n    running_loss = 0.0\n    for x_batch, y_batch in train_loader:\n        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n        optimizer.zero_grad()\n        preds = model(x_batch)\n        loss = criterion(preds, y_batch)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * x_batch.size(0)\n\n    train_loss = running_loss / len(train_loader.dataset)\n\n    \n    model.eval()\n    val_preds, val_targets = [], []\n    with torch.no_grad():\n        for x_val, y_val in val_loader:\n            x_val, y_val = x_val.to(device), y_val.to(device)\n            out = model(x_val)\n            val_preds.append(out.cpu().numpy())\n            val_targets.append(y_val.cpu().numpy())\n\n    val_preds = np.vstack(val_preds)\n    val_targets = np.vstack(val_targets)\n    val_loss = mean_squared_error(val_targets, val_preds)\n    r2 = r2_score(val_targets, val_preds)\n    mae = mean_absolute_error(val_targets, val_preds)\n\n    print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Val MSE={val_loss:.4f}, R={r2:.4f}, MAE={mae:.4f}\")\n\n\nfor i, component in enumerate(['skating_skills', 'transitions', 'performance', 'composition', 'interpretation']):\n    plt.figure(figsize=(5, 4))\n    plt.scatter(val_targets[:, i], val_preds[:, i], alpha=0.5)\n    plt.xlabel('True Score')\n    plt.ylabel('Predicted Score')\n    plt.title(f'{component} - True vs Predicted')\n    plt.plot([val_targets[:, i].min(), val_targets[:, i].max()],\n             [val_targets[:, i].min(), val_targets[:, i].max()], 'r--')\n    plt.grid(True)\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\n\nclass SkeletonPCSDataset(Dataset):\n    def __init__(self, manifest_df, npz_dir, seq_len=6000, mean=None, std=None):\n        self.df = manifest_df.reset_index(drop=True)\n        self.npz_dir = npz_dir\n        self.seq_len = seq_len\n        self.mean = mean\n        self.std = std\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        sample_id = row['sample_id']\n        data = np.load(os.path.join(self.npz_dir, sample_id + '.npz'))['reconstruction']\n        T, J, C = data.shape\n        x = data.reshape(T, J * C).astype(np.float32)\n\n        if T < self.seq_len:\n            pad = np.zeros((self.seq_len - T, J * C), dtype=np.float32)\n            x = np.vstack([x, pad])\n        else:\n            x = x[:self.seq_len]\n\n        if self.mean is not None and self.std is not None:\n            x = (x - self.mean) / (self.std + 1e-6)\n\n        y = np.array([\n            row['skating_skills'],\n            row['transitions'],\n            row['performance'],\n            row['composition'],\n            row['interpretation']\n        ], dtype=np.float32)\n\n        return torch.from_numpy(x), torch.from_numpy(y)\n\n\nclass LSTMRegressor(nn.Module):\n    def __init__(self, input_dim, hidden_dim=256, num_layers=2, output_dim=5, dropout=0.3):\n        super().__init__()\n        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x):\n        outs, _ = self.lstm(x)\n        return self.fc(outs[:, -1, :])\n\n\ndef compute_mean_std(npz_dir, sample_ids, seq_len):\n    all_data = []\n    for sid in sample_ids:\n        x = np.load(os.path.join(npz_dir, sid + '.npz'))['reconstruction']\n        T, J, C = x.shape\n        x = x.reshape(T, J*C)\n        if T < seq_len:\n            pad = np.zeros((seq_len - T, J*C))\n            x = np.vstack([x, pad])\n        else:\n            x = x[:seq_len]\n        all_data.append(x)\n    all_data = np.stack(all_data)\n    mean = np.mean(all_data, axis=(0, 1))\n    std = np.std(all_data, axis=(0, 1))\n    return mean.astype(np.float32), std.astype(np.float32)\n\n\nSEQ_LEN = 6000\nBATCH_SIZE = 16\nEPOCHS = 20\nNPZ_DIR = '/kaggle/input/finefs/skeleton/skeleton'\n\n# Split dataset\ntrain_df, test_df = train_test_split(pcs_df, test_size=0.2, random_state=42)\nmean, std = compute_mean_std(NPZ_DIR, train_df['sample_id'], SEQ_LEN)\n\ntrain_set = SkeletonPCSDataset(train_df, NPZ_DIR, seq_len=SEQ_LEN, mean=mean, std=std)\ntest_set  = SkeletonPCSDataset(test_df, NPZ_DIR, seq_len=SEQ_LEN, mean=mean, std=std)\n\ntrain_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\ntest_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\n\nsample_x, _ = train_set[0]\ninput_dim = sample_x.shape[1]\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = LSTMRegressor(input_dim=input_dim).to(device)\n\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n\n\nfor epoch in range(EPOCHS):\n    model.train()\n    train_loss = 0\n    for x_batch, y_batch in train_loader:\n        x_batch = x_batch.to(device)\n        y_batch = y_batch.to(device)\n\n        optimizer.zero_grad()\n        preds = model(x_batch)\n        loss = criterion(preds, y_batch)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item() * x_batch.size(0)\n\n    model.eval()\n    test_preds, test_targets = [], []\n    with torch.no_grad():\n        for x_batch, y_batch in test_loader:\n            x_batch = x_batch.to(device)\n            preds = model(x_batch).cpu().numpy()\n            test_preds.append(preds)\n            test_targets.append(y_batch.numpy())\n\n    test_preds = np.vstack(test_preds)\n    test_targets = np.vstack(test_targets)\n\n    epoch_loss = train_loss / len(train_set)\n    r2 = r2_score(test_targets, test_preds)\n    print(f\"Epoch {epoch+1} | Train Loss: {epoch_loss:.4f} | R: {r2:.4f}\")\n\n\nmae = mean_absolute_error(test_targets, test_preds)\nrmse = np.sqrt(mean_squared_error(test_targets, test_preds))\nr2 = r2_score(test_targets, test_preds)\n\nprint(f\"\\nFinal Evaluation:\\nMAE: {mae:.4f} | RMSE: {rmse:.4f} | R: {r2:.4f}\")\n\n\nfig, axes = plt.subplots(1, 5, figsize=(20, 4))\ntitles = ['Skating Skills', 'Transitions', 'Performance', 'Composition', 'Interpretation']\nfor i in range(5):\n    axes[i].scatter(test_targets[:, i], test_preds[:, i], alpha=0.5)\n    axes[i].plot([0, 10], [0, 10], 'r--')\n    axes[i].set_title(titles[i])\n    axes[i].set_xlabel('True')\n    axes[i].set_ylabel('Predicted')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}